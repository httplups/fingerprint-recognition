{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UACxZR8ciiUQ"
   },
   "source": [
    "# Basic operations in pytorch to build a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wz1OQ5nuzcZs"
   },
   "source": [
    "## Agenda\n",
    "*   Basic operations\n",
    "  *    Convolution\n",
    "  *    Activation\n",
    "  *    Pooling\n",
    "  *    Batch normalization\n",
    "  *    Skip conection\n",
    "  *    Linear\n",
    "  *    Dropout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F07sd5Oa_lce"
   },
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAnRUGQwlD7C"
   },
   "source": [
    "PyTorch has a module called `nn` that provides a lot of useful tools to build neural networks. This module defines most commonly used operations, such as convolution, pooling and activation. We will see how to use some of these operations using module `nn`: \n",
    "\n",
    "*   Convolution\n",
    "*   Activation\n",
    "*   Pooling\n",
    "*   Batch normalization\n",
    "*   Skip connection\n",
    "*   Linear transformation (dense layer) \n",
    "*   Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCdMfoJL_ii9"
   },
   "outputs": [],
   "source": [
    "#import module nn\n",
    "import torch\n",
    "from torch import nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p4eyRIkAYHq"
   },
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ffbtsg3Fr8I8"
   },
   "source": [
    "You must provide the number of input channels, the number of output channels (i.e., number of kernels), and the kernel sizes. To preserve image dimensions, you must provide the padding size. \n",
    "\n",
    "CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GulcMRYF_yMg"
   },
   "outputs": [],
   "source": [
    "#it defines a convolution with 3 kernels of sizes 5 x 3\n",
    "conv = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(5, 3), padding=(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIPiM70Bn-ib"
   },
   "source": [
    "The weights are stored in a tensor $K_{N, M, P, Q}$, such that\n",
    "$N$ is the number of kernels, $M$ is the number of input channels, $P$ and $Q$ are the input dimensions (height, width). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nAWDHZM-UmOO",
    "outputId": "83229aad-6f46-4b41-ee64-baca763b5160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(conv.weight.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znFB_adxsduZ"
   },
   "source": [
    "The input is a tensor $I_{B, M, P, Q}$, such that $B$ is the batch size, $M$ is the number of channels, and $P$ and $Q$ are the input dimensions (height, width). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jGgzqB0N_6Bn",
    "outputId": "deb325d2-3828-47ed-a930-131ae2e60d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[[[0.2747, 0.5139, 0.9980, 0.1989, 0.2224, 0.2705, 0.5520, 0.3759],\n",
      "          [0.2472, 0.1175, 0.4607, 0.7245, 0.8898, 0.8048, 0.3509, 0.7238],\n",
      "          [0.2432, 0.0657, 0.6150, 0.6342, 0.0737, 0.7929, 0.6359, 0.4524],\n",
      "          [0.8561, 0.0466, 0.6501, 0.2496, 0.8134, 0.0802, 0.7572, 0.2299],\n",
      "          [0.6945, 0.1838, 0.5563, 0.5890, 0.9777, 0.9087, 0.9511, 0.5522],\n",
      "          [0.7854, 0.8534, 0.9255, 0.8846, 0.7679, 0.3528, 0.8246, 0.0080],\n",
      "          [0.6089, 0.5250, 0.5178, 0.0272, 0.4649, 0.3583, 0.2552, 0.6432],\n",
      "          [0.1629, 0.3228, 0.7963, 0.7595, 0.3518, 0.0852, 0.9543, 0.1898],\n",
      "          [0.5945, 0.1053, 0.3386, 0.7561, 0.3266, 0.3605, 0.2470, 0.5566],\n",
      "          [0.7843, 0.4768, 0.6863, 0.1061, 0.8538, 0.1226, 0.3664, 0.9585]],\n",
      "\n",
      "         [[0.5546, 0.0042, 0.0342, 0.6536, 0.1061, 0.2885, 0.8680, 0.3073],\n",
      "          [0.2265, 0.1353, 0.8443, 0.9173, 0.8051, 0.7110, 0.3702, 0.1861],\n",
      "          [0.1571, 0.3355, 0.4285, 0.3836, 0.4881, 0.6915, 0.4885, 0.2060],\n",
      "          [0.0616, 0.8601, 0.0950, 0.3709, 0.4426, 0.6621, 0.4689, 0.5972],\n",
      "          [0.3736, 0.9513, 0.0703, 0.4644, 0.9031, 0.4935, 0.1075, 0.5352],\n",
      "          [0.1009, 0.0865, 0.7150, 0.4554, 0.7343, 0.4986, 0.8832, 0.3484],\n",
      "          [0.3839, 0.6939, 0.5219, 0.6283, 0.7201, 0.2869, 0.2583, 0.0985],\n",
      "          [0.4690, 0.0879, 0.2366, 0.4387, 0.3124, 0.0627, 0.3156, 0.0734],\n",
      "          [0.0794, 0.4080, 0.1240, 0.4011, 0.1786, 0.7539, 0.8515, 0.3627],\n",
      "          [0.7508, 0.5443, 0.0252, 0.0079, 0.7035, 0.8352, 0.0879, 0.9803]]]])\n",
      "torch.Size([1, 2, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "#creating a random input\n",
    "x = torch.rand(1, 2, 10, 8)\n",
    "print(\"x = \", x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmW5oc9wAMtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conv =  tensor([[[[-0.0753,  0.0723, -0.0450, -0.0397, -0.0630,  0.0128, -0.0710,\n",
      "           -0.1065],\n",
      "          [-0.0521,  0.0519,  0.0249,  0.2887,  0.2359,  0.2658,  0.1755,\n",
      "           -0.1148],\n",
      "          [ 0.0489, -0.0487,  0.2979,  0.0810,  0.2983, -0.0079,  0.0636,\n",
      "           -0.3524],\n",
      "          [ 0.0613,  0.0467,  0.1490, -0.0018, -0.0293,  0.1407, -0.0218,\n",
      "           -0.1965],\n",
      "          [ 0.0446,  0.2361, -0.0519,  0.2742,  0.2436,  0.3737,  0.1018,\n",
      "           -0.0897],\n",
      "          [ 0.1584,  0.1284,  0.3471,  0.2345,  0.2385,  0.2761, -0.0151,\n",
      "           -0.2450],\n",
      "          [ 0.0385,  0.0678,  0.2113,  0.1713,  0.0109,  0.0700, -0.0316,\n",
      "           -0.3056],\n",
      "          [ 0.1268, -0.0824, -0.0295,  0.1803,  0.1304, -0.0103, -0.1066,\n",
      "           -0.2881],\n",
      "          [ 0.0471,  0.0346,  0.0873,  0.0589,  0.1668,  0.1306,  0.2361,\n",
      "           -0.2836],\n",
      "          [ 0.1287,  0.2169,  0.1114,  0.0583,  0.0617,  0.3635,  0.3490,\n",
      "           -0.0523]],\n",
      "\n",
      "         [[-0.2016, -0.2361, -0.0240,  0.3436,  0.1633,  0.1138,  0.2934,\n",
      "            0.0672],\n",
      "          [-0.3194,  0.1268, -0.1468, -0.1029, -0.0291,  0.1686, -0.0517,\n",
      "           -0.0310],\n",
      "          [-0.3137,  0.5672, -0.1738,  0.2181, -0.0293,  0.0014,  0.0435,\n",
      "            0.4584],\n",
      "          [-0.2655,  0.2490, -0.1331,  0.2622,  0.5157,  0.5181,  0.1158,\n",
      "            0.4718],\n",
      "          [-0.1740,  0.1487, -0.0182,  0.2511, -0.1138,  0.1487,  0.0791,\n",
      "            0.3855],\n",
      "          [-0.3454, -0.0084, -0.1021,  0.1507,  0.1101, -0.0987,  0.1361,\n",
      "            0.3550],\n",
      "          [-0.3231,  0.2937,  0.0342,  0.0327,  0.1092,  0.4582,  0.0351,\n",
      "            0.2904],\n",
      "          [-0.1452,  0.1374,  0.0227,  0.1754,  0.1854,  0.0945,  0.1365,\n",
      "            0.4334],\n",
      "          [-0.2543,  0.2597, -0.1396, -0.1334, -0.0766,  0.3473, -0.1262,\n",
      "            0.0873],\n",
      "          [-0.2958, -0.1487, -0.1768, -0.0224,  0.0496, -0.0939, -0.2518,\n",
      "           -0.1163]],\n",
      "\n",
      "         [[ 0.1585,  0.1887,  0.2477,  0.2191,  0.3569,  0.2783,  0.0980,\n",
      "           -0.2934],\n",
      "          [ 0.0946,  0.3467,  0.4534,  0.1152,  0.0892,  0.3361, -0.0941,\n",
      "           -0.2881],\n",
      "          [ 0.4319,  0.1796,  0.3176,  0.2716,  0.2068,  0.1570, -0.0295,\n",
      "           -0.3346],\n",
      "          [ 0.3928,  0.2793,  0.5755,  0.3774,  0.1756,  0.3260, -0.1148,\n",
      "           -0.4460],\n",
      "          [ 0.8024,  0.0759,  0.1034,  0.3755,  0.2944, -0.1176,  0.0500,\n",
      "           -0.4394],\n",
      "          [ 0.6068, -0.0146,  0.1838,  0.2068,  0.1507,  0.1808,  0.1329,\n",
      "           -0.3898],\n",
      "          [ 0.4949,  0.3965,  0.1211,  0.2859,  0.1687,  0.1102,  0.1018,\n",
      "           -0.6118],\n",
      "          [ 0.4987, -0.0281,  0.1878,  0.1568,  0.1073,  0.1251,  0.2287,\n",
      "           -0.2098],\n",
      "          [ 0.3398,  0.1573,  0.1387,  0.1473,  0.0707,  0.0737,  0.4989,\n",
      "           -0.3202],\n",
      "          [ 0.3871, -0.2152, -0.0450,  0.1465,  0.1027,  0.0391,  0.0024,\n",
      "           -0.1336]]]], grad_fn=<ThnnConv2DBackward>)\n",
      "torch.Size([1, 3, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "#Convolving x with the three kernels that have already been randomly initialized\n",
    "y_conv = conv(x)\n",
    "print(\"y_conv = \", y_conv)\n",
    "print(y_conv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4kuaU58CtqfE"
   },
   "source": [
    "We can also set the kernel weights as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XV21oH6IBZnS"
   },
   "outputs": [],
   "source": [
    "#initializing weights and biases\n",
    "conv.weight.data = torch.rand(3, 2, 5, 3, requires_grad=True) - 0.5\n",
    "conv.bias.data   = torch.rand(3, requires_grad=True) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRb2j6YlFxRH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conv =  tensor([[[[ 5.2458e-01,  9.6723e-01,  1.1288e+00,  1.6674e+00,  1.2163e+00,\n",
      "            1.0846e+00,  1.5027e+00,  1.0782e+00],\n",
      "          [ 9.9878e-01,  7.5285e-01,  5.8623e-01,  9.8847e-01,  2.0301e+00,\n",
      "            1.1511e+00,  1.5072e+00,  9.9631e-01],\n",
      "          [ 1.1690e+00,  8.4741e-01,  5.6139e-01,  1.0843e+00,  6.2335e-01,\n",
      "            1.3435e+00,  1.7858e+00,  8.9234e-01],\n",
      "          [ 2.8727e-01,  1.0836e+00,  1.5026e+00,  1.4574e+00,  1.6782e+00,\n",
      "            1.0704e+00,  1.3914e+00,  1.0564e+00],\n",
      "          [ 3.3891e-01,  1.7468e+00,  1.8551e+00,  1.2152e+00,  9.1561e-01,\n",
      "            2.2041e+00,  1.5428e-01,  7.9786e-01],\n",
      "          [ 3.4737e-01,  8.5049e-01,  7.0544e-01,  1.5567e+00,  1.0281e+00,\n",
      "            2.0754e-01,  1.1201e+00,  5.9992e-01],\n",
      "          [ 8.8233e-01,  8.2734e-01,  4.3024e-01,  7.9497e-01,  1.2342e+00,\n",
      "            1.3178e+00,  1.9594e-01,  1.1652e+00],\n",
      "          [ 8.7477e-01,  7.8832e-01,  8.5719e-01,  3.1546e-01,  1.5816e+00,\n",
      "            6.5240e-01,  1.4775e+00,  6.2472e-01],\n",
      "          [ 5.1927e-01,  5.8592e-01, -5.6616e-02,  5.0545e-01,  4.2035e-01,\n",
      "            3.9516e-01,  5.0796e-01,  6.0523e-01],\n",
      "          [ 1.8880e-01,  5.1363e-01,  5.5258e-01, -1.8496e-01, -2.8153e-01,\n",
      "           -5.8289e-02,  3.8860e-01, -1.9196e-01]],\n",
      "\n",
      "         [[-6.4640e-02,  1.4342e-03,  5.2186e-01,  4.6647e-03,  1.4920e-01,\n",
      "           -1.3491e-01, -6.7836e-01,  1.7395e-01],\n",
      "          [-2.1426e-02, -4.1244e-01, -5.4951e-01, -5.3072e-01, -5.0674e-01,\n",
      "            6.0958e-01, -1.4819e-02,  6.3786e-02],\n",
      "          [ 4.1928e-01, -8.8360e-02, -2.5080e-01,  3.7380e-01,  6.1597e-01,\n",
      "           -6.4896e-01,  2.9568e-01,  4.0215e-02],\n",
      "          [ 7.7914e-01, -4.2243e-01,  1.8503e-01, -4.1058e-01,  1.6734e-01,\n",
      "           -4.8500e-01, -6.3570e-03, -5.6296e-01],\n",
      "          [-1.6475e-01, -3.9965e-01, -1.8746e-01, -9.7331e-01,  1.9778e-01,\n",
      "           -2.7273e-01,  1.0373e+00, -1.6616e-01],\n",
      "          [ 1.0019e-01,  3.3674e-01,  2.5889e-01, -2.9223e-01, -3.2033e-01,\n",
      "           -1.7638e-01, -3.2821e-01, -1.7112e-02],\n",
      "          [-1.0308e+00, -1.7318e-01, -2.1424e-02, -3.8519e-01, -7.9968e-01,\n",
      "            5.6322e-02,  2.2754e-01, -1.3134e-01],\n",
      "          [ 3.4778e-01, -5.7565e-01, -2.5983e-01,  2.2654e-01,  1.7092e-01,\n",
      "            1.6024e-01,  2.8306e-03,  9.2878e-01],\n",
      "          [ 1.9027e-01, -1.4273e-01, -3.4538e-01, -3.9691e-01,  4.7604e-01,\n",
      "           -4.4623e-01, -2.3000e-01,  4.7292e-01],\n",
      "          [-3.9501e-01, -1.1933e-01,  7.4237e-02, -7.4137e-01, -1.6397e-01,\n",
      "            3.2364e-01, -5.3587e-01,  2.2689e-01]],\n",
      "\n",
      "         [[-1.5094e-01,  1.0419e+00,  7.6200e-01,  5.9243e-01,  7.2550e-01,\n",
      "            5.3869e-01,  8.2108e-01, -8.5658e-02],\n",
      "          [ 1.0824e-01,  4.6796e-01,  1.9631e-01,  3.9332e-01,  6.4213e-01,\n",
      "            2.5556e-01,  6.3170e-01,  1.8690e-01],\n",
      "          [ 2.6631e-01,  1.4543e+00,  9.0274e-01,  1.1244e+00,  9.1124e-01,\n",
      "            1.9998e+00,  1.1727e+00,  1.0969e+00],\n",
      "          [ 3.4127e-01,  1.2429e+00,  1.5328e+00,  2.5417e+00,  1.8707e+00,\n",
      "            1.5513e+00,  1.3949e+00,  5.3832e-01],\n",
      "          [ 2.2859e-02,  1.3602e+00,  1.2130e+00,  1.5330e+00,  1.2213e+00,\n",
      "            1.9879e+00,  8.0970e-01,  6.9073e-01],\n",
      "          [ 1.0430e+00,  1.3399e+00,  9.9725e-01,  1.7665e+00,  6.2134e-01,\n",
      "            7.5632e-01,  9.1937e-01,  3.7741e-01],\n",
      "          [ 5.6842e-01,  9.8232e-01,  8.8138e-01,  8.8051e-01,  1.3295e+00,\n",
      "            1.6071e+00,  1.1059e+00,  1.0376e+00],\n",
      "          [ 6.6845e-01,  2.0465e+00,  1.4994e+00,  1.0674e+00,  1.3745e+00,\n",
      "            1.8320e+00,  1.5776e+00,  8.0613e-01],\n",
      "          [ 1.5233e-01,  5.5754e-01,  5.7356e-01,  1.2599e+00, -2.2258e-02,\n",
      "            1.1085e-01,  3.8828e-01, -1.7199e-01],\n",
      "          [-3.3189e-01,  2.6054e-01,  3.0612e-01,  4.2975e-01, -2.8498e-01,\n",
      "           -3.5959e-01, -3.2130e-01, -3.9748e-01]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>)\n",
      "torch.Size([1, 3, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "#Convolving x with our new kernel bank of three kernels\n",
    "y_conv = conv(x)\n",
    "print(\"y_conv = \", y_conv)\n",
    "print(y_conv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNk_uCdTGv1B"
   },
   "source": [
    "\n",
    "### Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kN1eYB9zZqN"
   },
   "source": [
    "Now we define a ReLU activation function.\n",
    "\n",
    "CLASS torch.nn.ReLU(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJqb6tldGow7"
   },
   "outputs": [],
   "source": [
    "#defining relu function\n",
    "\n",
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euCH4HNfGp38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_relu =  tensor([[[[5.2458e-01, 9.6723e-01, 1.1288e+00, 1.6674e+00, 1.2163e+00,\n",
      "           1.0846e+00, 1.5027e+00, 1.0782e+00],\n",
      "          [9.9878e-01, 7.5285e-01, 5.8623e-01, 9.8847e-01, 2.0301e+00,\n",
      "           1.1511e+00, 1.5072e+00, 9.9631e-01],\n",
      "          [1.1690e+00, 8.4741e-01, 5.6139e-01, 1.0843e+00, 6.2335e-01,\n",
      "           1.3435e+00, 1.7858e+00, 8.9234e-01],\n",
      "          [2.8727e-01, 1.0836e+00, 1.5026e+00, 1.4574e+00, 1.6782e+00,\n",
      "           1.0704e+00, 1.3914e+00, 1.0564e+00],\n",
      "          [3.3891e-01, 1.7468e+00, 1.8551e+00, 1.2152e+00, 9.1561e-01,\n",
      "           2.2041e+00, 1.5428e-01, 7.9786e-01],\n",
      "          [3.4737e-01, 8.5049e-01, 7.0544e-01, 1.5567e+00, 1.0281e+00,\n",
      "           2.0754e-01, 1.1201e+00, 5.9992e-01],\n",
      "          [8.8233e-01, 8.2734e-01, 4.3024e-01, 7.9497e-01, 1.2342e+00,\n",
      "           1.3178e+00, 1.9594e-01, 1.1652e+00],\n",
      "          [8.7477e-01, 7.8832e-01, 8.5719e-01, 3.1546e-01, 1.5816e+00,\n",
      "           6.5240e-01, 1.4775e+00, 6.2472e-01],\n",
      "          [5.1927e-01, 5.8592e-01, 0.0000e+00, 5.0545e-01, 4.2035e-01,\n",
      "           3.9516e-01, 5.0796e-01, 6.0523e-01],\n",
      "          [1.8880e-01, 5.1363e-01, 5.5258e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 3.8860e-01, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 1.4342e-03, 5.2186e-01, 4.6647e-03, 1.4920e-01,\n",
      "           0.0000e+00, 0.0000e+00, 1.7395e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           6.0958e-01, 0.0000e+00, 6.3786e-02],\n",
      "          [4.1928e-01, 0.0000e+00, 0.0000e+00, 3.7380e-01, 6.1597e-01,\n",
      "           0.0000e+00, 2.9568e-01, 4.0215e-02],\n",
      "          [7.7914e-01, 0.0000e+00, 1.8503e-01, 0.0000e+00, 1.6734e-01,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9778e-01,\n",
      "           0.0000e+00, 1.0373e+00, 0.0000e+00],\n",
      "          [1.0019e-01, 3.3674e-01, 2.5889e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.6322e-02, 2.2754e-01, 0.0000e+00],\n",
      "          [3.4778e-01, 0.0000e+00, 0.0000e+00, 2.2654e-01, 1.7092e-01,\n",
      "           1.6024e-01, 2.8306e-03, 9.2878e-01],\n",
      "          [1.9027e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7604e-01,\n",
      "           0.0000e+00, 0.0000e+00, 4.7292e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 7.4237e-02, 0.0000e+00, 0.0000e+00,\n",
      "           3.2364e-01, 0.0000e+00, 2.2689e-01]],\n",
      "\n",
      "         [[0.0000e+00, 1.0419e+00, 7.6200e-01, 5.9243e-01, 7.2550e-01,\n",
      "           5.3869e-01, 8.2108e-01, 0.0000e+00],\n",
      "          [1.0824e-01, 4.6796e-01, 1.9631e-01, 3.9332e-01, 6.4213e-01,\n",
      "           2.5556e-01, 6.3170e-01, 1.8690e-01],\n",
      "          [2.6631e-01, 1.4543e+00, 9.0274e-01, 1.1244e+00, 9.1124e-01,\n",
      "           1.9998e+00, 1.1727e+00, 1.0969e+00],\n",
      "          [3.4127e-01, 1.2429e+00, 1.5328e+00, 2.5417e+00, 1.8707e+00,\n",
      "           1.5513e+00, 1.3949e+00, 5.3832e-01],\n",
      "          [2.2859e-02, 1.3602e+00, 1.2130e+00, 1.5330e+00, 1.2213e+00,\n",
      "           1.9879e+00, 8.0970e-01, 6.9073e-01],\n",
      "          [1.0430e+00, 1.3399e+00, 9.9725e-01, 1.7665e+00, 6.2134e-01,\n",
      "           7.5632e-01, 9.1937e-01, 3.7741e-01],\n",
      "          [5.6842e-01, 9.8232e-01, 8.8138e-01, 8.8051e-01, 1.3295e+00,\n",
      "           1.6071e+00, 1.1059e+00, 1.0376e+00],\n",
      "          [6.6845e-01, 2.0465e+00, 1.4994e+00, 1.0674e+00, 1.3745e+00,\n",
      "           1.8320e+00, 1.5776e+00, 8.0613e-01],\n",
      "          [1.5233e-01, 5.5754e-01, 5.7356e-01, 1.2599e+00, 0.0000e+00,\n",
      "           1.1085e-01, 3.8828e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 2.6054e-01, 3.0612e-01, 4.2975e-01, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00]]]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#applying the relu function to output of a convolution\n",
    "y_relu = relu(y_conv)\n",
    "print(\"y_relu = \",y_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-C32PFOzHoJI"
   },
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTAQUZ2Q0sN4"
   },
   "source": [
    "We may define now max poolin. Note that strides greater than 1 will reduce the input size. \n",
    "\n",
    "CLASS torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWeA5kA8HeK4"
   },
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJZUQLWdH2-7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pool =  tensor([[[[9.9878e-01, 1.6674e+00, 2.0301e+00, 1.5072e+00],\n",
      "          [1.1690e+00, 1.5026e+00, 2.0301e+00, 1.7858e+00],\n",
      "          [1.7468e+00, 1.8551e+00, 2.2041e+00, 2.2041e+00],\n",
      "          [8.8233e-01, 1.5567e+00, 1.5816e+00, 1.4775e+00],\n",
      "          [8.7477e-01, 8.5719e-01, 1.5816e+00, 1.4775e+00]],\n",
      "\n",
      "         [[1.4342e-03, 5.2186e-01, 6.0958e-01, 6.0958e-01],\n",
      "          [7.7914e-01, 3.7380e-01, 6.1597e-01, 6.0958e-01],\n",
      "          [7.7914e-01, 3.3674e-01, 1.9778e-01, 1.0373e+00],\n",
      "          [3.4778e-01, 3.3674e-01, 2.2654e-01, 9.2878e-01],\n",
      "          [3.4778e-01, 2.2654e-01, 4.7604e-01, 9.2878e-01]],\n",
      "\n",
      "         [[1.0419e+00, 1.0419e+00, 7.2550e-01, 8.2108e-01],\n",
      "          [1.4543e+00, 2.5417e+00, 2.5417e+00, 1.9998e+00],\n",
      "          [1.3602e+00, 2.5417e+00, 2.5417e+00, 1.9879e+00],\n",
      "          [2.0465e+00, 2.0465e+00, 1.8320e+00, 1.8320e+00],\n",
      "          [2.0465e+00, 2.0465e+00, 1.8320e+00, 1.8320e+00]]]],\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "torch.Size([1, 3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "#applying max pooling to output of ReLu\n",
    "y_pool = pool(y_relu)\n",
    "print(\"y_pool = \", y_pool)\n",
    "print(y_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXdqFTYZXkz1"
   },
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMzMfrvq16l-"
   },
   "source": [
    "Now we may define batch normalization to normalize batches in the following way $$y = \\frac{x - \\mathbb{E}[x]}{\\sqrt{\\mathrm{Var}[x]}+\\epsilon}\\gamma + \\beta.$$ You must indicate the number of input channels (num_features).\n",
    "\n",
    "\n",
    "CLASS torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwbKQ3LK5VfZ"
   },
   "outputs": [],
   "source": [
    "#defining batch normalization layer\n",
    "norm = nn.BatchNorm2d(num_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "946BtTY85shc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_norm =  tensor([[[[-1.3426,  0.2873,  1.1715, -0.1031],\n",
      "          [-0.9276, -0.1143,  1.1715,  0.5761],\n",
      "          [ 0.4809,  0.7450,  1.5958,  1.5958],\n",
      "          [-1.6264,  0.0176,  0.0782, -0.1756],\n",
      "          [-1.6449, -1.6877,  0.0782, -0.1756]],\n",
      "\n",
      "         [[-1.8967,  0.0270,  0.3513,  0.3513],\n",
      "          [ 0.9780, -0.5202,  0.3749,  0.3513],\n",
      "          [ 0.9780, -0.6572, -1.1709,  1.9324],\n",
      "          [-0.6164, -0.6572, -1.0646,  1.5312],\n",
      "          [-0.6164, -1.0646, -0.1423,  1.5312]],\n",
      "\n",
      "         [[-1.3832, -1.3832, -1.9562, -1.7832],\n",
      "          [-0.6364,  1.3330,  1.3330,  0.3516],\n",
      "          [-0.8068,  1.3330,  1.3330,  0.3300],\n",
      "          [ 0.4362,  0.4362,  0.0476,  0.0476],\n",
      "          [ 0.4362,  0.4362,  0.0476,  0.0476]]]],\n",
      "       grad_fn=<NativeBatchNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "#applying batch normalization\n",
    "y_norm = norm(y_pool)\n",
    "print(\"y_norm = \", y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxsxUHlk6in6"
   },
   "source": [
    "### Skip connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pktxly2T7Wau"
   },
   "source": [
    "To skip layers without passing through previus layers, we may concatenate the output of two layers along a given axis. For instance, we may concatenate the input and output of relu as follows.\n",
    "\n",
    "torch.cat(tensors, dim=0, *, out=None) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkbib1Lk8fPv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat =  tensor([[[[0.0119, 0.1887, 0.8797, 0.7958, 0.2105, 0.3933, 0.3611, 0.2529],\n",
      "          [0.1982, 0.5942, 0.2462, 0.4993, 0.3310, 0.6911, 0.3058, 0.5796],\n",
      "          [0.5084, 0.7411, 0.8538, 0.5789, 0.7895, 0.8870, 0.4857, 0.3698],\n",
      "          [0.4434, 0.7200, 0.4169, 0.2557, 0.4328, 0.0125, 0.7869, 0.9360],\n",
      "          [0.0312, 0.2187, 0.5572, 0.3212, 0.5839, 0.2899, 0.6221, 0.9115],\n",
      "          [0.4448, 0.1916, 0.2809, 0.9075, 0.8867, 0.9891, 0.0174, 0.9108],\n",
      "          [0.7690, 0.3055, 0.9843, 0.8632, 0.9101, 0.4176, 0.6827, 0.8616],\n",
      "          [0.4205, 0.2882, 0.3889, 0.0679, 0.0190, 0.2159, 0.4348, 0.7251],\n",
      "          [0.4136, 0.5189, 0.5231, 0.2470, 0.7173, 0.6770, 0.7782, 0.3758],\n",
      "          [0.7322, 0.0176, 0.5811, 0.6094, 0.9380, 0.5153, 0.1153, 0.6833]],\n",
      "\n",
      "         [[0.3919, 0.9493, 0.9453, 0.6607, 0.5304, 0.4389, 0.2849, 0.4201],\n",
      "          [0.3739, 0.9339, 0.3109, 0.5884, 0.2848, 0.6622, 0.5391, 0.0582],\n",
      "          [0.9036, 0.6026, 0.3229, 0.5628, 0.1724, 0.6641, 0.2110, 0.9666],\n",
      "          [0.4803, 0.5300, 0.2056, 0.8637, 0.4842, 0.5904, 0.1868, 0.4056],\n",
      "          [0.2769, 0.8258, 0.3250, 0.2346, 0.0342, 0.2456, 0.7786, 0.2622],\n",
      "          [0.0086, 0.5851, 0.8313, 0.9885, 0.1822, 0.8221, 0.7368, 0.8210],\n",
      "          [0.9603, 0.4148, 0.3095, 0.7557, 0.1117, 0.7269, 0.0782, 0.9534],\n",
      "          [0.2659, 0.8504, 0.7147, 0.6704, 0.3451, 0.1918, 0.4987, 0.4415],\n",
      "          [0.1183, 0.1604, 0.2330, 0.9666, 0.6697, 0.8808, 0.7090, 0.8577],\n",
      "          [0.7815, 0.7548, 0.3538, 0.6709, 0.2072, 0.7992, 0.9845, 0.2306]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1288, 0.0000, 0.0000, 0.1394, 0.0626, 0.2339],\n",
      "          [0.1637, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0674, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1790, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0032, 0.0202, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2295, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.1125, 0.4729, 0.7947, 0.2117, 0.2805, 0.0000, 0.0000],\n",
      "          [0.0035, 0.0000, 0.0000, 0.0000, 0.0000, 0.2651, 0.1472, 0.5627],\n",
      "          [0.0000, 0.0000, 0.0000, 0.3049, 0.0000, 0.0745, 0.0000, 0.0000],\n",
      "          [0.0590, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0388],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0806, 0.0000, 0.1966],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.4158, 0.0000, 0.0000, 0.5286],\n",
      "          [0.4585, 0.3632, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4091],\n",
      "          [0.1948, 0.0000, 0.2586, 0.0366, 0.7605, 0.5167, 0.9863, 0.5199],\n",
      "          [0.7754, 0.4361, 0.5052, 0.2183, 0.1986, 0.5231, 0.2003, 0.7972]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.3498, 0.3286, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3626, 0.3621, 0.4170, 0.3087, 0.4786, 0.7414, 0.0000],\n",
      "          [0.1054, 0.0000, 0.2486, 0.0000, 0.0000, 0.0182, 0.3117, 0.1293],\n",
      "          [0.0000, 0.1732, 0.1604, 0.2294, 0.3958, 0.0000, 0.0882, 0.0000],\n",
      "          [0.0000, 0.0000, 0.4170, 0.0000, 0.0000, 0.0000, 0.2112, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.4870, 0.4713, 0.6896, 0.0000, 0.3693],\n",
      "          [0.1265, 0.0575, 0.0000, 0.0000, 0.8794, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3970, 0.4825, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0532, 0.2314, 0.1468, 0.5010],\n",
      "          [0.0000, 0.2611, 0.1248, 0.0000, 0.2599, 0.1216, 0.2441, 0.1443]]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "torch.Size([1, 5, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "#concatenating tensors\n",
    "concat = torch.cat((x, y_relu), dim=1)\n",
    "print(\"concat = \", concat)\n",
    "print(concat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L04BvhVaMF8g"
   },
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ba9bi_dX9-RR"
   },
   "source": [
    "Dense layers can be implemented by flattening output activations followed by a linear transformation. We must indicate the input and output sizes.\n",
    "\n",
    "torch.flatten(input, start_dim=0, end_dim=-1) → Tensor\n",
    "\n",
    "CLASS torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BffJeqoYKQgz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 60])\n"
     ]
    }
   ],
   "source": [
    "#transforming it into a 2D tensor\n",
    "y_flatten = y_pool.flatten(start_dim=1)\n",
    "print(y_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCzjDwz0MPda"
   },
   "outputs": [],
   "source": [
    "#defining the linear layer\n",
    "linear = nn.Linear(in_features=60, out_features=2, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AP5e4LInMgm-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2201,  1.0148]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "#applying linear the transformation\n",
    "y_linear = linear(y_flatten)\n",
    "print(y_linear)\n",
    "print(y_linear.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regularization, we may also add a dropout layer to randomly disconsider elements of the input tensor (it sets zeroes) with probability p by following a Bernoulli distribution. The outputs are scaled by a factor $\\frac{1}{1-p}$ during training. \n",
    "\n",
    "CLASStorch.nn.Dropout(p=0.5, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = drop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropout:  tensor([[-0.6510,  0.9346,  0.4056,  0.8617, -0.4832],\n",
      "        [-1.4813, -0.7307, -1.4605, -2.3998, -1.3143],\n",
      "        [-1.9054,  0.1042, -0.3983, -0.3800, -0.2123],\n",
      "        [-0.1725,  1.0847, -0.1320, -0.1492, -0.6975],\n",
      "        [ 0.0759, -0.3639, -3.0578,  0.9329,  1.1660]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before dropout: \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropout tensor([[-1.3020,  0.0000,  0.8111,  1.7235, -0.9664],\n",
      "        [-2.9626, -1.4614, -2.9210, -0.0000, -2.6286],\n",
      "        [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000, -0.2639, -0.2985, -1.3949],\n",
      "        [ 0.0000, -0.0000, -6.1156,  1.8658,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"After dropout\", y)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "presentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
